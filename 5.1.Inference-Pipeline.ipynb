{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 5.1] Inferencde Pipeline 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Pipeline <a class=\"anchor\" id=\"pipeline_setup\"></a>\n",
    "\n",
    "아래 그림과 같이 위에서 생성한 전처리, Custom PCA , XGboost, 후처리의 네가지 모델을 가지고 1개의 단일 모델을 만들어 Inference Pipleline을 생성 합니다. <br>\n",
    "**입력 데이타 가공이 없이 실제 데이타가 입력이 되면, 1개의 단일 모델을 통해서 최종적으로 예측 결과인 True, False의 결과 값이 제공 됩니다.**\n",
    "\n",
    "![Fig.4.1.inference-pipeline-4-models](img/Fig.4.1.inference-pipeline-4-models.png)\n",
    "\n",
    "\n",
    "**Machine Learning Model Pipeline (Inference Pipeline)는 create_model() 를 호출하여 만들 수 있습니다.** <br>\n",
    "예를 들어 여기서는 the fitted Scikit-learn inference model, custom PCA model, the fitted Xgboost model and the psotprocessing model 의 네가지 모델을 가지고 만듦니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import boto3\n",
    "from time import strftime, gmtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_name = 'churn-inference-pipeline-' + timestamp_prefix\n",
    "client = boto3.client('sagemaker')\n",
    "response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            'Image': preprocessor_image_name,\n",
    "            'ModelDataUrl': preprocessor_model_data,\n",
    "            'Environment': {\n",
    "                    \"SAGEMAKER_SUBMIT_DIRECTORY\": preprocessor_uploaded_code_s3_prefix,\n",
    "                    \"TRANSFORM_MODE\": \"feature-transform\",\n",
    "                    \"SAGEMAKER_PROGRAM\": preprocessor_uploaded_code_script_name\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            'Image': pca_image_uri,\n",
    "            'ModelDataUrl': pca_model_data,\n",
    "            'Environment': {}\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            'Image': xgb_image_uri,\n",
    "            'ModelDataUrl': xgb_model_data,\n",
    "            \"Environment\": {}\n",
    "        },\n",
    "        {\n",
    "            'Image': preprocessor_image_name,\n",
    "            'ModelDataUrl': preprocessor_model_data,\n",
    "            'Environment': {\n",
    "                    \"SAGEMAKER_SUBMIT_DIRECTORY\": preprocessor_uploaded_code_s3_prefix,\n",
    "                    \"TRANSFORM_MODE\": \"inverse-label-transform\",\n",
    "                    \"SAGEMAKER_PROGRAM\": preprocessor_uploaded_code_script_name\n",
    "                \n",
    "                }\n",
    "        },\n",
    "    ],\n",
    "    ExecutionRoleArn = role,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline_model_name = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_pipeline_model_name: \n",
      " churn-inference-pipeline-2020-08-26-12-29-35\n"
     ]
    }
   ],
   "source": [
    "print(\"inference_pipeline_model_name: \\n\", inference_pipeline_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'inference_pipeline_model_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store inference_pipeline_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
