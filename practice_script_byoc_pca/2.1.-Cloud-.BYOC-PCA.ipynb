{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Local Script-Mode Custom Training Container</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "057716757052\n",
      "us-east-2\n",
      "arn:aws:iam::057716757052:role/service-role/AmazonSageMaker-ExecutionRole-20191128T110038\n",
      "sagemaker-us-east-2-057716757052\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = 'sagemaker-training-containers/'\n",
    "prefix = 'pca'\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = get_execution_role()\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the Dockerfile which defines the statements for building our custom SageMaker training container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp pca_byoc_train.py docker/code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting docker/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile docker/Dockerfile\n",
    "\n",
    "FROM 257758044811.dkr.ecr.us-east-2.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3\n",
    "    \n",
    "# install python package\n",
    "RUN pip install joblib\n",
    "\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "\n",
    "ENV PATH=\"/opt/ml/code:${PATH}\"\n",
    "\n",
    "# Copy training code\n",
    "COPY code/* /opt/ml/code/\n",
    " \n",
    "WORKDIR /opt/ml/code\n",
    "\n",
    "# ENTRYPOINT [\"python\", \"pca_train.py\"]\n",
    "# In order to use SageMaker Env varaibles, use the statement below\n",
    "ENV SAGEMAKER_PROGRAM pca_byoc_train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['account_id'] = account_id\n",
    "os.environ['region'] = region\n",
    "os.environ['ecr_repository_name'] = ecr_repository_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-2\n",
      "057716757052\n",
      "sagemaker-training-containers/pca\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  8.192kB\n",
      "Step 1/8 : FROM 257758044811.dkr.ecr.us-east-2.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3\n",
      " ---> 30adb1aa9af5\n",
      "Step 2/8 : RUN pip install joblib\n",
      " ---> Using cache\n",
      " ---> 0574906c196e\n",
      "Step 3/8 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 72f929011350\n",
      "Step 4/8 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 7b2b4471af62\n",
      "Step 5/8 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 2fc403c35061\n",
      "Step 6/8 : COPY code/* /opt/ml/code/\n",
      " ---> Using cache\n",
      " ---> ee3e072fe015\n",
      "Step 7/8 : WORKDIR /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> ce3bf2231241\n",
      "Step 8/8 : ENV SAGEMAKER_PROGRAM pca_byoc_train.py\n",
      " ---> Using cache\n",
      " ---> 3fce6e3c6d6a\n",
      "Successfully built 3fce6e3c6d6a\n",
      "Successfully tagged sagemaker-training-containers/pca:latest\n",
      "Login Succeeded\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws:ecr:us-east-2:057716757052:repository/sagemaker-training-containers/pca\",\n",
      "            \"registryId\": \"057716757052\",\n",
      "            \"repositoryName\": \"sagemaker-training-containers/pca\",\n",
      "            \"repositoryUri\": \"057716757052.dkr.ecr.us-east-2.amazonaws.com/sagemaker-training-containers/pca\",\n",
      "            \"createdAt\": 1597127900.0,\n",
      "            \"imageTagMutability\": \"MUTABLE\",\n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "The push refers to repository [057716757052.dkr.ecr.us-east-2.amazonaws.com/sagemaker-training-containers/pca]\n",
      "57edae3e7223: Preparing\n",
      "ecd304237caf: Preparing\n",
      "969e46b772a5: Preparing\n",
      "cfe0cbc5dd2c: Preparing\n",
      "23b3530769e5: Preparing\n",
      "8be6c85c96e4: Preparing\n",
      "a5a688002069: Preparing\n",
      "4b7dff825027: Preparing\n",
      "ccdb13a20bf2: Preparing\n",
      "9513cdf4e497: Preparing\n",
      "7f083f9454c0: Preparing\n",
      "29f36b5893dc: Preparing\n",
      "8be6c85c96e4: Waiting\n",
      "a5a688002069: Waiting\n",
      "4b7dff825027: Waiting\n",
      "ccdb13a20bf2: Waiting\n",
      "9513cdf4e497: Waiting\n",
      "29f36b5893dc: Waiting\n",
      "57edae3e7223: Layer already exists\n",
      "cfe0cbc5dd2c: Layer already exists\n",
      "969e46b772a5: Layer already exists\n",
      "ecd304237caf: Layer already exists\n",
      "23b3530769e5: Layer already exists\n",
      "8be6c85c96e4: Layer already exists\n",
      "9513cdf4e497: Layer already exists\n",
      "a5a688002069: Layer already exists\n",
      "4b7dff825027: Layer already exists\n",
      "ccdb13a20bf2: Layer already exists\n",
      "7f083f9454c0: Layer already exists\n",
      "29f36b5893dc: Layer already exists\n",
      "latest: digest: sha256:2a04b2c0a87093932309aa47ea489aa17fa78f8609eed12ad82a0e20c262d8f3 size: 2840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "ACCOUNT_ID=${account_id}\n",
    "REGION=${region}\n",
    "REPO_NAME=${ecr_repository_name}\n",
    "\n",
    "echo $REGION\n",
    "echo $ACCOUNT_ID\n",
    "echo $REPO_NAME\n",
    "\n",
    "\n",
    "# Get the login command from ECR in order to pull down the Tensorflow-gpu:1.5 image\n",
    "$(aws ecr get-login --registry-ids 257758044811 --region ${region} --no-include-email)\n",
    "\n",
    "\n",
    "\n",
    "docker build -f docker/Dockerfile -t $REPO_NAME docker\n",
    "\n",
    "docker tag $REPO_NAME $ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com/$REPO_NAME:latest\n",
    "\n",
    "$(aws ecr get-login --no-include-email --registry-ids $ACCOUNT_ID)\n",
    "\n",
    "aws ecr describe-repositories --repository-names $REPO_NAME || aws ecr create-repository --repository-name $REPO_NAME\n",
    "\n",
    "docker push $ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com/$REPO_NAME:latest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "057716757052.dkr.ecr.us-east-2.amazonaws.com/sagemaker-training-containers/pca:latest\n"
     ]
    }
   ],
   "source": [
    "container_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training with Amazon SageMaker</h3>\n",
    "\n",
    "Once we have correctly pushed our container to Amazon ECR, we are ready to start training with Amazon SageMaker, which requires the ECR path to the Docker container used for training as parameter for starting a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input:  s3://sagemaker-us-east-2-057716757052/Scikit-pca-custom/data\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "train_X = iris.data\n",
    "train_y = iris.target\n",
    "\n",
    "os.makedirs('./data', exist_ok =True)\n",
    "np.savetxt('./data/iris.csv', train_X, delimiter=',',\n",
    "           fmt='%1.3f, %1.3f, %1.3f, %1.3f'\n",
    "          )\n",
    "\n",
    "WORK_DIRECTORY = 'data'\n",
    "prefix = 'Scikit-pca-custom'\n",
    "train_input = sagemaker_session.upload_data(WORK_DIRECTORY,\n",
    "                                            key_prefix=\"{}/{}\".format(prefix, WORK_DIRECTORY)\n",
    "                                           )\n",
    "print(\"train_input: \", train_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can execute the training job by calling the fit() method of the generic Estimator object defined in the Amazon SageMaker Python SDK (https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/estimator.py). This corresponds to calling the CreateTrainingJob() API (https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-11 12:39:38 Starting - Starting the training job...\n",
      "2020-08-11 12:39:41 Starting - Launching requested ML instances.........\n",
      "2020-08-11 12:41:16 Starting - Preparing the instances for training......\n",
      "2020-08-11 12:42:30 Downloading - Downloading input data\n",
      "2020-08-11 12:42:30 Training - Downloading the training image........\u001b[34m2020-08-11 12:43:44,249 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-08-11 12:43:44,252 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 12:43:44,273 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-11 12:43:44,274 sagemaker-containers INFO     Module pca_byoc_train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-08-11 12:43:44,275 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-08-11 12:43:44,275 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-08-11 12:43:44,275 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pca-byoc-train\n",
      "  Building wheel for pca-byoc-train (setup.py): started\n",
      "  Building wheel for pca-byoc-train (setup.py): finished with status 'done'\n",
      "  Created wheel for pca-byoc-train: filename=pca_byoc_train-1.0.0-py2.py3-none-any.whl size=7851 sha256=d8aeb48698c99bde9bdd9828d55309388454ec1c5639b5be78268eb8187932e3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ebq07p31/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built pca-byoc-train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pca-byoc-train\u001b[0m\n",
      "\u001b[34mSuccessfully installed pca-byoc-train-1.0.0\u001b[0m\n",
      "\u001b[34m2020-08-11 12:43:45,576 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-11 12:43:45,589 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"n_components\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"Scikit-pca-custom-2020-08-11-12-39-38-354\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"pca_byoc_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pca_byoc_train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"n_components\":2}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=pca_byoc_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=pca_byoc_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"n_components\":2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"Scikit-pca-custom-2020-08-11-12-39-38-354\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"pca_byoc_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"pca_byoc_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--n_components\",\"2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_N_COMPONENTS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pca_byoc_train --n_components 2\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mtrain shape:  (150, 4)\u001b[0m\n",
      "\u001b[34mComponent Variability: \n",
      " [0.92461872 0.05306648]\u001b[0m\n",
      "\u001b[34m2020-08-11 12:43:46,903 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-08-11 12:43:55 Uploading - Uploading generated training model\n",
      "2020-08-11 12:43:55 Completed - Training job completed\n",
      "Training seconds: 99\n",
      "Billable seconds: 99\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "# instance_type = 'local'\n",
    "instance_type = 'ml.m4.xlarge'\n",
    "\n",
    "pca_estimator = sagemaker.estimator.Estimator(container_image_uri,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type= instance_type,\n",
    "                                    base_job_name=prefix)\n",
    "\n",
    "pca_estimator.set_hyperparameters(n_components= 2)\n",
    "\n",
    "train_config = sagemaker.session.s3_input(train_input, content_type='text/csv')\n",
    "\n",
    "pca_estimator.fit({'train': train_config})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-057716757052/Scikit-pca-custom-2020-08-11-12-39-38-354/output/model.tar.gz'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# instance_type = 'local'\n",
    "instance_type = 'ml.m4.xlarge'\n",
    "\n",
    "predictor = pca_estimator.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = instance_type,\n",
    "    serializer=csv_serializer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "# from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "# import sagemaker\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# pca_predictor = RealTimePredictor(\n",
    "# #     endpoint = predictor.endpoint,\n",
    "#     endpoint = 'Scikit-pca-custom-2020-08-11-08-34-11-899',    \n",
    "# #     sagemaker_session = sagemaker_session,\n",
    "#     sagemaker_session = None,    \n",
    "#     serializer = csv_serializer,\n",
    "#     content_type = CONTENT_TYPE_CSV,\n",
    "#     accept = CONTENT_TYPE_JSON\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sample:  (2, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample = train_X[0:1].reshape(1,-1) # Single Sample (1,-1)\n",
    "sample = train_X[0:2]\n",
    "print(\"Shape of sample: \", sample.shape)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sample = [[1 , 2 , 3 , 50]]\n",
    "# sample = [1 , 2 , 3 , 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[[-2.6841256259695343, 0.31939724658510066], [-2.714141687294324, -0.17700122506478091]]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sample:  (1, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample = train_X[0:1].reshape(1,-1) # Single Sample (1,-1)\n",
    "sample = train_X[0:1]\n",
    "print(\"Shape of sample: \", sample.shape)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[[-2.6841256259695347, 0.3193972465851006]]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
