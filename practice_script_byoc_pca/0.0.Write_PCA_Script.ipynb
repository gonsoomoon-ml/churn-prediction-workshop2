{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Script-Mode Custom Training Container</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pca_script_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pca_script_train.py\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "    \n",
    "    parser.add_argument('--n_components', type=int, default = 3)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    input_files = [ os.path.join(args.train, file) for file in os.listdir(args.train)]\n",
    "    if len(input_files) == 0:\n",
    "        raise ValueError(('There are no files in {}.\\n' +\n",
    "                          'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                          'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                          'does not have permission to access the data.').format(args.train, \"train\"))\n",
    "    raw_data = [ pd.read_csv(file, header=None, engine=\"python\") for file in input_files]\n",
    "    train_data = pd.concat(raw_data)\n",
    "    \n",
    "    pca = PCA(n_components = args.n_components)\n",
    "    print(\"train shape: \", train_data.shape)\n",
    "    X_new = pca.fit_transform(train_data)\n",
    "    \n",
    "    print(\"Component Variability: \\n\", pca.explained_variance_ratio_)\n",
    "    \n",
    "    joblib.dump(pca, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "    \n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Deserialized and return fitted model\n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"   \n",
    "    pca = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    \n",
    "    return pca  \n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Preprocess input data\n",
    "    \n",
    "    We implement this because the default predict_fn uses .predict(), but our model is a preprocessor\n",
    "    so we want to use .transform().\n",
    "    \"\"\"\n",
    "    logging.info(f\"predict_fn: input_data - '{input_data}'\")\n",
    "    # model, PCA model, has transform()\n",
    "    components = model.transform(input_data)\n",
    "    \n",
    "    logging.info(f\"predict_fn: PCA components: \\n'{components}'\")    \n",
    "    return components\n",
    "    \n",
    "# predict_fn을 정의하지 않으면 default predict_fn을 호출 함.\n",
    "# PCA는 predict 함수를 제공하지 않으므로 사용자 정의 필요 함.\n",
    "\n",
    "# algo-1-dhteh_1  | 2020-08-10 14:15:55,970 ERROR - pca_train - Exception on /invocations [POST]\n",
    "# algo-1-dhteh_1  | Traceback (most recent call last):\n",
    "# algo-1-dhteh_1  |   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
    "# algo-1-dhteh_1  |     return fn(*args, **kwargs)\n",
    "# algo-1-dhteh_1  |   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_sklearn_container/serving.py\", line 70, in default_predict_fn\n",
    "# algo-1-dhteh_1  |     output = model.predict(input_data)\n",
    "# algo-1-dhteh_1  | AttributeError: 'PCA' object has no attribute 'predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pca_byoc_train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pca_byoc_train.py\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging\n",
    "from io import StringIO\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])\n",
    "    \n",
    "    parser.add_argument('--n_components', type=int, default = 3)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    input_files = [ os.path.join(args.train, file) for file in os.listdir(args.train)]\n",
    "    if len(input_files) == 0:\n",
    "        raise ValueError(('There are no files in {}.\\n' +\n",
    "                          'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                          'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                          'does not have permission to access the data.').format(args.train, \"train\"))\n",
    "    raw_data = [ pd.read_csv(file, header=None, engine=\"python\") for file in input_files]\n",
    "    train_data = pd.concat(raw_data)\n",
    "    \n",
    "    pca = PCA(n_components = args.n_components)\n",
    "    print(\"train shape: \", train_data.shape)\n",
    "    X_new = pca.fit_transform(train_data)\n",
    "    \n",
    "    print(\"Component Variability: \\n\", pca.explained_variance_ratio_)\n",
    "    \n",
    "    joblib.dump(pca, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "    \n",
    "def input_fn(input_data, request_content_type):\n",
    "    \"\"\"Parse input data payload\n",
    "    \n",
    "    We currently only take csv input. Since we need to process both labelled\n",
    "    and unlabelled data we first determine whether the label column is present\n",
    "    by looking at how many columns were provided.\n",
    "    \"\"\"\n",
    "        \n",
    "    content_type = request_content_type.lower(\n",
    "    ) if request_content_type else \"text/csv\"\n",
    "    content_type = content_type.split(\";\")[0].strip()\n",
    "        \n",
    "    \n",
    "    if isinstance(input_data, str):\n",
    "        str_buffer = input_data\n",
    "    else:\n",
    "        # str_buffer = str(input_data,'utf-8')\n",
    "        str_buffer = input_data\n",
    "    \n",
    "    if (content_type == 'text/csv' or content_type == 'text/csv; charset=utf-8'):\n",
    "        # Read the raw input data as CSV.\n",
    "        df = pd.read_csv(StringIO(str_buffer),  header=None)\n",
    "        logging.info(f\"input_fn: \")      \n",
    "        logging.info(f\"shape of requested data: '{df.shape}'\")        \n",
    "        logging.info(f\"requested data: '{df}'\")\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"{} not supported by script!\".format(content_type))    \n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Deserialized and return fitted model\n",
    "    Note that this should have the same name as the serialized model in the main method\n",
    "    \"\"\"   \n",
    "    pca = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    \n",
    "    return pca  \n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Preprocess input data\n",
    "    \n",
    "    We implement this because the default predict_fn uses .predict(), but our model is a preprocessor\n",
    "    so we want to use .transform().\n",
    "    \"\"\"\n",
    "    logging.info(f\"predict_fn: input_data - '{input_data}'\")\n",
    "    # model, PCA model, has transform()\n",
    "    components = model.transform(input_data)\n",
    "    \n",
    "    logging.info(f\"predict_fn: PCA components: \\n'{components}'\")    \n",
    "    return components\n",
    "    \n",
    "# predict_fn을 정의하지 않으면 default predict_fn을 호출 함.\n",
    "# PCA는 predict 함수를 제공하지 않으므로 사용자 정의 필요 함.\n",
    "\n",
    "# algo-1-dhteh_1  | 2020-08-10 14:15:55,970 ERROR - pca_train - Exception on /invocations [POST]\n",
    "# algo-1-dhteh_1  | Traceback (most recent call last):\n",
    "# algo-1-dhteh_1  |   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_functions.py\", line 93, in wrapper\n",
    "# algo-1-dhteh_1  |     return fn(*args, **kwargs)\n",
    "# algo-1-dhteh_1  |   File \"/miniconda3/lib/python3.7/site-packages/sagemaker_sklearn_container/serving.py\", line 70, in default_predict_fn\n",
    "# algo-1-dhteh_1  |     output = model.predict(input_data)\n",
    "# algo-1-dhteh_1  | AttributeError: 'PCA' object has no attribute 'predict'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
